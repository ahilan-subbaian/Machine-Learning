{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS559 - F20 Project #1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task Desciption\n",
    "You are provided with an anonymized dataset containing numeric feature variables, the binary target column, and a string ID_code column.\n",
    "\n",
    "The task is to predict the value of `target` column in the test set using either **Logistic Regression** and **SVM**. You are welcome to use **regularizaiton**. \n",
    "\n",
    "## File descriptions\n",
    "- train.csv - the training set (202 columns)\n",
    "\n",
    "- test.csv - the test set. The test set contains some rows which are not included in scoring.\n",
    "\n",
    "## Rules\n",
    "- The data does not have specific column names. Therefore, you will not know what data is about. \n",
    "- However, you still can do classicaition problem without clustering the training set. **No unsupervised learning techniques in this project**. \n",
    "- There are 202 columns. This means that the key of high accuracy comes from **EDA** and **feature enegineering**. \n",
    "- There are no rules on EDA and Feature Engineering. \n",
    "- On your model, make sure you can reduce the columns at the most of 25%. If we use all columns, we may have high computational cost and getting into bias-variance tradeoff and underfit vs. overfit situations. \n",
    "- The project is out of 100. \n",
    "    - 50 points will come from your EDA and any pre-processing work. \n",
    "    - 30 points will come from your model: Accuracy + overcoming any ML challenges. \n",
    "    - 10 points will come from in-class competition. \n",
    "        - Ranking the accuracy with less features. \n",
    "    - 10 points will come from a report describing your work flow and model evaluations.\n",
    "        - must be submitted in different file (e.g., pdf, docx). \n",
    "        \n",
    "## Recommand Before-Preprocessing\n",
    "- You can split the set from the data distribution. \n",
    "- You can make multiple new data frames by randomly selecting columns. \n",
    "- You can do similar by rows. \n",
    "\n",
    "## Recommand Before-training model\n",
    "- Make sure to delete features from supportive reasons. \n",
    "\n",
    "Proejct DUE: 10/23/2020 Friday 11:59 PM. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All my import statements to run the methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.feature_selection import RFE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from matplotlib.colors import ListedColormap\n",
    "from sklearn.metrics import confusion_matrix \n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_classif\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load training data\n",
    "#ID column did not seem relevant\n",
    "data = pd.read_csv('train.csv').drop(columns = ['ID_code'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load test data\n",
    "data2 = pd.read_csv('test.csv').drop(columns = ['ID_code'])\n",
    "target = pd.read_csv('test_target.csv').drop(columns = ['ID_code'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = data.drop(columns = ['target'])\n",
    "# transformer = Normalizer().fit(x)  # fit does nothing.\n",
    "# x = transformer.transform(x)\n",
    "y = data['target']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initial Test Run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ran a logistic regression test run using all the features just to get a sense of how well the prediction algorithm works when utilizing all the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = StandardScaler()\n",
    "x_sc = sc.fit_transform(x)\n",
    "lr = LogisticRegression()\n",
    "lr.fit(x_sc, y)\n",
    "y_pred = lr.predict(x_sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[177450   2452]\n",
      " [ 14645   5453]]\n",
      "accuracy score 0.915\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y, y_pred))\n",
    "print('accuracy score %.3f' %(accuracy_score(y, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model seems to predict decently well with .915 accuracy, the mose error seems to be from predicting 1s properly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = data.corr()\n",
    "# correlation matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since correlation matrix is too large to read line by line, I opted to find the largest correlation in the whole table and the largest correlation among all the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "82\n",
      "0.08091733227447406\n",
      "27\n",
      "140\n",
      "0.009844361358419677\n"
     ]
    }
   ],
   "source": [
    "a = 0 #index of largest correlation\n",
    "b = 0 #index of largest correlation\n",
    "a1 = 0 #index of largest feature correlation\n",
    "b1 = 0 #index of largest feature correlation\n",
    "maxs = 0 #max correlation value\n",
    "maxs2 = 0 #max feature correlation value\n",
    "for i in range(len(corr)):\n",
    "    for j in range(i + 1, len(corr)):\n",
    "#         corrs.append(corr.iloc[i, j])\n",
    "        if i != j and abs(corr.iloc[i, j]) > maxs:\n",
    "            a = i\n",
    "            b = j\n",
    "            maxs = abs(corr.iloc[i, j])\n",
    "        if i != j and abs(corr.iloc[i, j]) > maxs2 and i != 0:\n",
    "            a1 = i\n",
    "            b1 = j\n",
    "            maxs2 = abs(corr.iloc[i, j])\n",
    "\n",
    "print(a) \n",
    "print(b)\n",
    "print(maxs) \n",
    "print(a1) \n",
    "print(b1)\n",
    "print(maxs2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 3., 11., 21., 20., 26., 30., 27., 34., 18., 10.]),\n",
       " array([-0.08091733, -0.06615251, -0.0513877 , -0.03662288, -0.02185806,\n",
       "        -0.00709324,  0.00767157,  0.02243639,  0.03720121,  0.05196603,\n",
       "         0.06673085]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#seperated the row for target\n",
    "corrs = corr['target'][1:]\n",
    "corrs.shape\n",
    "plt.hist(corrs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a left skewed relationship within the data, since I want highest correlation (sign does not matter) I opted to test all the features with under abs(.01) correlation to see how much these features will impact the results found in my initial logistic regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "161"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keep = (corrs > .01) | (corrs < -.01) # remove features bellow abs(.01)\n",
    "names = data.drop(columns = ['target']).columns\n",
    "sum(keep) #number of features kept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200000, 161)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = data.drop(columns = ['target'])[names[keep]]\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc = StandardScaler()\n",
    "x_sc = sc.fit_transform(x)\n",
    "lr = LogisticRegression()\n",
    "lr.fit(x_sc, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = lr.predict(x_sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[177455   2447]\n",
      " [ 14665   5433]]\n",
      "accuracy score 0.914\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y, y_pred))\n",
    "print('accuracy score %.3f' %(accuracy_score(y, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model without the 39 features seems to perform the same as my model with all the features. In the preference for less features it seems significant to remove the features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To confirm my prediction I ran another regression using just the 39 features that I initially removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Run a logistic regression with correlations between .01 and -.01\n",
    "# corrs = np.array(corrs)\n",
    "keep = (corrs <= .01) & (corrs >= -.01)\n",
    "sum(keep) # number of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200000, 39)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = data.drop(columns = ['target'])[names[keep]]\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = StandardScaler()\n",
    "x_sc = sc.fit_transform(x)\n",
    "lr = LogisticRegression()\n",
    "lr = lr.fit(x_sc, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = lr.predict(x_sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[179902      0]\n",
      " [ 20098      0]]\n",
      "accuracy score 0.900\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y, y_pred))\n",
    "print('accuracy score %.3f' %(accuracy_score(y, y_pred)))\n",
    "#clearly the not correlated values seem to not be able to predict the y column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This validates my belief that I can remove these variabls without noticing significant changes to my accuracy since these variables failed to predict any ones when they exists a significant 20% in the training data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "set my keep to a boolean array that keeps all correlations above .01 and less than -.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This will be my preliminary training set\n",
    "keep = (corrs > .01) | (corrs < -.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try lasso and ridge regression (I want to see if any of the features are not adding a signficant margin to the prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200000, 200)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = data.drop(columns = ['target'])\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = StandardScaler()\n",
    "x_sc = sc.fit_transform(x)\n",
    "lr = LogisticRegression(penalty = 'elasticnet', l1_ratio = 1, solver = 'saga', C = .1)\n",
    "lr = lr.fit(x_sc, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = lr.predict(x_sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(lr.coef_[0] == 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is one feature that l1 finds not significant. I'll compare this with keep to see if there is an overlap between my prior eda and this eda."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(lr.coef_[0] == 0 & keep) # there is overlap, l1 can be disregarded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I run a l2 logistic regression to validate removing the 39 features from before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(penalty = 'elasticnet', l1_ratio = 0, solver = 'saga', C = .1)\n",
    "lr = lr.fit(x_sc, y)\n",
    "y_pred = lr.predict(x_sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To look at all the coefficient values below .0294 I can see that the 24 least significant (by using absolute value) features match up with the 34 values from keep."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "alpha = 0.0294\n",
    "print(sum((abs(lr.coef_[0]) < alpha)))\n",
    "print(sum((abs(lr.coef_[0]) < alpha) & keep) == sum((abs(lr.coef_[0]) < alpha)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make sure that I do not overfit to the training data (and not have excessive computation time), I decided to split my data into 10 parts to run each of my 10 models. This should be fine since I have 20,000 rows per model which should be enough to still capture the underlying trend.\n",
    "\n",
    "It is important in this case that I shuffle the data to make sure that any trends from saving the data does not influence my models (only since I am splitting)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#shuffle, incase the dataframe is sorted\n",
    "data = data.sample(frac=1).reset_index(drop=True) #sample randomly takes from the data set, frac = 1 means it takes all the values\n",
    "x = data.drop(columns = ['target'])\n",
    "y = data['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "final = [] #store model estimates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = len(x) // 10\n",
    "x_train = [x[(i*(a)):(((i + 1)*(a)))] for i in range(10)]\n",
    "# x_train[0]\n",
    "y_train = [y[(i*(a)):(((i + 1)*(a)))] for i in range(10)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I chose to train my first 9 models using the eda from the prior section. For my last model I chose to include another one to test what my models would look like without removing any variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(9):\n",
    "    x_train[i] = x_train[i][names[keep]] # names is the columns and keep from before stores the higher correlation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function for running my logistic regression models.\n",
    "\n",
    "input(x, y, output = true) -> Logistic Regression\n",
    "\n",
    "x - matrix of features, y - target, output - print accuracy, Logistic Regression - contains the coeffcient values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regression(x, y, output = True):\n",
    "#     sc = StandardScaler()\n",
    "#     x_sc = sc.fit_transform(x)\n",
    "    x_sc = preprocessing.normalize(x)\n",
    "#     x_sc = x\n",
    "    lr = LogisticRegression()\n",
    "    lr.fit(x_sc, y)\n",
    "    y_pred = lr.predict(x_sc)\n",
    "    if output:\n",
    "        a = confusion_matrix(y, y_pred)\n",
    "        print(a)\n",
    "        b = accuracy_score(y, y_pred)\n",
    "        print('accuracy score %.3f' %(b))\n",
    "        return lr, [len(lr.coef_[0])] + [a[0][0]] + [a[0][1]] +[a[1][0]] +[a[1][1]] + [b]\n",
    "    return lr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilize selectKbest function which performs a comparision using f_classify to rank each of the features compared to the target boolean value. SelectKbest then choses the k highest ranking features to keep.\n",
    "\n",
    "f_classify was chose since it is the python function for ANOVA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20000, 50)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# transformer = MinMaxScaler().fit_transform(x_train[0])\n",
    "transformer = preprocessing.normalize(x_train[0])\n",
    "# transformer = x_train[0]\n",
    "lr_1 = SelectKBest(f_classif, k=50)\n",
    "x_1 = lr_1.fit_transform(transformer, y_train[0])\n",
    "x_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[17941    52]\n",
      " [ 1874   133]]\n",
      "accuracy score 0.904\n"
     ]
    }
   ],
   "source": [
    "# m1 = regression(x_1, y_train[0])\n",
    "m1, a = regression(x_train[0][x_train[0].columns[lr_1.get_support()]], y_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "final.append(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RFECV is a function that uses a ranker (logistic regression) to remove features that are not significant (this can end up with more than 50) - uses cross validation at n = 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer = MinMaxScaler().fit_transform(x_train[1])\n",
    "# transformer = Normalizer().fit_transform(x_train[1])\n",
    "estimator = LogisticRegression(penalty = 'none')\n",
    "selector_2 = RFECV(estimator, min_features_to_select=50, step=10)\n",
    "selector_2 = selector_2.fit(transformer, y_train[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20000, 151)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_2 = selector_2.transform(transformer)\n",
    "x_2.shape #not removing till 50 features, if chosen I will need to process more"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[17958     5]\n",
      " [ 1941    96]]\n",
      "accuracy score 0.903\n"
     ]
    }
   ],
   "source": [
    "m2, a = regression(x_2, y_train[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "final.append(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RFE uses an estimator (Logistic Regression fitted with an l1 penalty) and recursively removes 10 every iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer = MinMaxScaler().fit_transform(x_train[2])\n",
    "estimator = LogisticRegression(penalty = 'elasticnet', l1_ratio = 1, solver = 'saga')\n",
    "selector_3 = RFE(estimator, n_features_to_select=50, step=10)\n",
    "selector_3 = selector_3.fit(transformer, y_train[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20000, 50)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_3 = selector_3.transform(transformer)\n",
    "x_3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[17971    34]\n",
      " [ 1859   136]]\n",
      "accuracy score 0.905\n"
     ]
    }
   ],
   "source": [
    "m3, a = regression(x_3, y_train[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "final.append(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar to the prior model, however I use an l2 penalty to rank the coefficients this time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_sc = StandardScaler().fit_transform(x_train[3])\n",
    "# transformer = MinMaxScaler().fit_transform(x_train[2])\n",
    "lr = LogisticRegression(penalty = 'elasticnet', l1_ratio = 0, solver = 'saga', C = .1)\n",
    "selector_4 = RFE(lr, n_features_to_select = 50, step = 10)\n",
    "selector_4 = selector_4.fit(x_sc, y_train[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20000, 50)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_4 = selector_4.transform(x_sc)\n",
    "x_4.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[17881   114]\n",
      " [ 1794   211]]\n",
      "accuracy score 0.905\n"
     ]
    }
   ],
   "source": [
    "m4, a = regression(x_4, y_train[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "final.append(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar to the prior two models, however this one penalizes each feature based on a combination of l1 and l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_sc = StandardScaler().fit_transform(x_train[4])\n",
    "# transformer = MinMaxScaler().fit_transform(x_train[2])\n",
    "lr = LogisticRegression(penalty = 'elasticnet', l1_ratio = 0.5, solver = 'saga', C = 0.1)\n",
    "selector_5 = RFE(lr, n_features_to_select = 50, step = 10)\n",
    "selector_5 = selector_5.fit(x_sc, y_train[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20000, 50)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_5 = selector_5.transform(x_sc)\n",
    "x_5.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[17875   131]\n",
      " [ 1799   195]]\n",
      "accuracy score 0.903\n"
     ]
    }
   ],
   "source": [
    "m5, a = regression(x_5, y_train[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "final.append(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Easy function to call a SVC classifier\n",
    "\n",
    "input(x, y, output = true, C = 1, kernel = 'rbf, gamma = 'scale') -> SVC object\n",
    "\n",
    "x - matrix of features, y - target, output - print accuracy, C & K & gamma - inputs for SVC all are set to the default paramters, SVC - contains the coeffcient values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mySVC(x, y, output = True, C = 1, kernel = 'rbf', gamma = 'scale'):\n",
    "    clf = make_pipeline(StandardScaler(), SVC(C = C, kernel = kernel, gamma = gamma))\n",
    "    clf.fit(x, y)\n",
    "    y_pred = clf.predict(x)\n",
    "#     x_sc = StandardScaler().fit_transform(x)\n",
    "#     x_sc = preprocessing.normalize(x)\n",
    "#     classy = SVC(gamma = 'auto', degree = 1, kernel = 'sigmoid')\n",
    "#     classy = classy.fit(x_sc, y)\n",
    "#     y_pred = classy.predict(x_sc)\n",
    "    if output:\n",
    "        a = confusion_matrix(y, y_pred)\n",
    "        print(a)\n",
    "        b = accuracy_score(y, y_pred)\n",
    "        print('accuracy score %.3f' %(b))\n",
    "        return clf, [len(x.columns)] + [a[0][0]] + [a[0][1]] +[a[1][0]] +[a[1][1]] + [b]\n",
    "    return clf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the features from model 1, but training using an SVC model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[17928     0]\n",
      " [  896  1176]]\n",
      "accuracy score 0.955\n"
     ]
    }
   ],
   "source": [
    "m6, a = mySVC(x_train[5][x_train[5].columns[lr_1.get_support()]], y_train[5], C = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "final.append(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I iteratively looked for the combination of C values, kernel and gamma that would perform best on the data. I chose to comment out because it took very long to run, but I added all the outputs below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in [.05, .1, .5, 1, 2, 5]:\n",
    "#     for j in ['rbf', 'sigmoid']:\n",
    "#         for k in ['scale', 'auto']:\n",
    "#             print(\"\\n\" + str(i) + \" \" + j + \" \" + k)\n",
    "#             mySVC(x_train[5][x_train[5].columns[lr_1.get_support()]], y_train[5], C = i, kernel = j, gamma = k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0.05 rbf scale\n",
    "[[17945     0]\n",
    " [ 2055     0]]\n",
    "accuracy score 0.897\n",
    "\n",
    "0.05 rbf auto\n",
    "[[17945     0]\n",
    " [ 2055     0]]\n",
    "accuracy score 0.897\n",
    "\n",
    "0.05 sigmoid scale\n",
    "[[17945     0]\n",
    " [ 2055     0]]\n",
    "accuracy score 0.897\n",
    "\n",
    "0.05 sigmoid auto\n",
    "[[17945     0]\n",
    " [ 2055     0]]\n",
    "accuracy score 0.897\n",
    "\n",
    "0.1 rbf scale\n",
    "[[17945     0]\n",
    " [ 2055     0]]\n",
    "accuracy score 0.897\n",
    "\n",
    "0.1 rbf auto\n",
    "[[17945     0]\n",
    " [ 2055     0]]\n",
    "accuracy score 0.897\n",
    "\n",
    "0.1 sigmoid scale\n",
    "[[17945     0]\n",
    " [ 2055     0]]\n",
    "accuracy score 0.897\n",
    "\n",
    "0.1 sigmoid auto\n",
    "[[17945     0]\n",
    " [ 2055     0]]\n",
    "accuracy score 0.897\n",
    "\n",
    "0.5 rbf scale\n",
    "[[17945     0]\n",
    " [ 2051     4]]\n",
    "accuracy score 0.897\n",
    "\n",
    "0.5 rbf auto\n",
    "[[17945     0]\n",
    " [ 2051     4]]\n",
    "accuracy score 0.897\n",
    "\n",
    "0.5 sigmoid scale\n",
    "[[17945     0]\n",
    " [ 2055     0]]\n",
    "accuracy score 0.897\n",
    "\n",
    "0.5 sigmoid auto\n",
    "[[17945     0]\n",
    " [ 2055     0]]\n",
    "accuracy score 0.897\n",
    "\n",
    "1 rbf scale\n",
    "[[17945     0]\n",
    " [ 1653   402]]\n",
    "accuracy score 0.917\n",
    "\n",
    "1 rbf auto\n",
    "[[17945     0]\n",
    " [ 1653   402]]\n",
    "accuracy score 0.917\n",
    "\n",
    "1 sigmoid scale\n",
    "[[17934    11]\n",
    " [ 2055     0]]\n",
    "accuracy score 0.897\n",
    "\n",
    "1 sigmoid auto\n",
    "[[17934    11]\n",
    " [ 2055     0]]\n",
    "accuracy score 0.897\n",
    "\n",
    "2 rbf scale\n",
    "[[17942     3]\n",
    " [  841  1214]]\n",
    "accuracy score 0.958\n",
    "\n",
    "2 rbf auto\n",
    "[[17942     3]\n",
    " [  841  1214]]\n",
    "accuracy score 0.958\n",
    "\n",
    "2 sigmoid scale\n",
    "[[17622   323]\n",
    " [ 2055     0]]\n",
    "accuracy score 0.881\n",
    "\n",
    "2 sigmoid auto\n",
    "[[17622   323]\n",
    " [ 2055     0]]\n",
    "accuracy score 0.881\n",
    "\n",
    "5 rbf scale\n",
    "[[17945     0]\n",
    " [  164  1891]]\n",
    "accuracy score 0.992\n",
    "\n",
    "5 rbf auto\n",
    "[[17945     0]\n",
    " [  164  1891]]\n",
    "accuracy score 0.992\n",
    "\n",
    "5 sigmoid scale\n",
    "[[16453  1492]\n",
    " [ 2041    14]]\n",
    "accuracy score 0.823\n",
    "\n",
    "5 sigmoid auto\n",
    "[[16453  1492]\n",
    " [ 2041    14]]\n",
    "accuracy score 0.823"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At a simple glance, C = 5 & kernel = 'rbf' appears to be the best model with a performance of .992. However, I want to focus on my bias and variance ratio which indicates that a score of .992 will increase my bias to this specific model (the training set) too much. So I chose to pick the C = 2 & kernel = 'rbf' (I chose gamme = 'scale' which is the defaut) as a more optimal model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the features from model 2, but training using an SVC model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[17974     0]\n",
      " [  871  1155]]\n",
      "accuracy score 0.956\n"
     ]
    }
   ],
   "source": [
    "m7, a = mySVC(x_train[6][x_train[6].columns[selector_2.get_support()]], y_train[6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "final.append(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the features from model 3, but training using an SVC model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[18011     1]\n",
      " [  895  1093]]\n",
      "accuracy score 0.955\n"
     ]
    }
   ],
   "source": [
    "m8, a = mySVC(x_train[7][x_train[7].columns[selector_3.get_support()]], y_train[7], C = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "final.append(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Used Select from model which chooses the coefficients based on an estimator (ExtraTreesClassifier) to pick 50 features. ExtraTreesClassifier runs by splitting the data into uncorrelated sections and assigning rankings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.feature_selection import SelectFromModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = ExtraTreesClassifier(n_estimators=50)\n",
    "clf = clf.fit(x_train[8], y_train[8])\n",
    "model = SelectFromModel(clf, threshold = -np.inf, max_features = 50, prefit=True)\n",
    "x_9 = model.transform(x_train[8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20000, 50)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_9.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[17978    27]\n",
      " [ 1908    87]]\n",
      "accuracy score 0.903\n"
     ]
    }
   ],
   "source": [
    "m9, a = regression(x_9, y_train[8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "final.append(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the model that does not use the eda processing and I wanted to see how RFE would perform on such a data set to show the impact of removing the values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = data.sample(frac=1).reset_index(drop=True)\n",
    "# x = data.drop(columns = ['target'])\n",
    "# y = data['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer = StandardScaler().fit_transform(x_train[9])\n",
    "# transformer = Normalizer().fit_transform(x_train[1])\n",
    "estimator = LogisticRegression(penalty = 'none')\n",
    "selector_10 = RFE(estimator, n_features_to_select=50, step=10)\n",
    "selector_10 = selector_10.fit(transformer, y_train[9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20000, 50)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_10 = selector_10.transform(transformer)\n",
    "x_10.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[17908   113]\n",
      " [ 1773   206]]\n",
      "accuracy score 0.906\n"
     ]
    }
   ],
   "source": [
    "m10, a = regression(x_10, y_train[9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "final.append(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I created this simple function to see if features are being repeated between the models (model 2 removed since greater than 50 chose features) (models 6, 7, 8 removed because they use features chosen from previous models). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = [lr_1.get_support(), selector_3.get_support(), selector_4.get_support(), \n",
    "     selector_5.get_support(), model.get_support(), selector_10.get_support()[keep]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 5false\n",
      "5 4false\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(m)):\n",
    "    for j in range(len(m)):\n",
    "        if i != j and sum(m[i] & m[j]) > 41:\n",
    "            print(str(i) + \" \" + str(j) + \"false\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No output so none of the models share more than 41 features with another model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pick model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th># of Features</th>\n",
       "      <th>True Positive</th>\n",
       "      <th>False Negative</th>\n",
       "      <th>False Positive</th>\n",
       "      <th>True Negative</th>\n",
       "      <th>Accuracy Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>17941</td>\n",
       "      <td>52</td>\n",
       "      <td>1874</td>\n",
       "      <td>133</td>\n",
       "      <td>0.90370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>151</td>\n",
       "      <td>17958</td>\n",
       "      <td>5</td>\n",
       "      <td>1941</td>\n",
       "      <td>96</td>\n",
       "      <td>0.90270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>50</td>\n",
       "      <td>17971</td>\n",
       "      <td>34</td>\n",
       "      <td>1859</td>\n",
       "      <td>136</td>\n",
       "      <td>0.90535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50</td>\n",
       "      <td>17881</td>\n",
       "      <td>114</td>\n",
       "      <td>1794</td>\n",
       "      <td>211</td>\n",
       "      <td>0.90460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>50</td>\n",
       "      <td>17875</td>\n",
       "      <td>131</td>\n",
       "      <td>1799</td>\n",
       "      <td>195</td>\n",
       "      <td>0.90350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>50</td>\n",
       "      <td>17928</td>\n",
       "      <td>0</td>\n",
       "      <td>896</td>\n",
       "      <td>1176</td>\n",
       "      <td>0.95520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>151</td>\n",
       "      <td>17974</td>\n",
       "      <td>0</td>\n",
       "      <td>871</td>\n",
       "      <td>1155</td>\n",
       "      <td>0.95645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>50</td>\n",
       "      <td>18011</td>\n",
       "      <td>1</td>\n",
       "      <td>895</td>\n",
       "      <td>1093</td>\n",
       "      <td>0.95520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>50</td>\n",
       "      <td>17978</td>\n",
       "      <td>27</td>\n",
       "      <td>1908</td>\n",
       "      <td>87</td>\n",
       "      <td>0.90325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>50</td>\n",
       "      <td>17908</td>\n",
       "      <td>113</td>\n",
       "      <td>1773</td>\n",
       "      <td>206</td>\n",
       "      <td>0.90570</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    # of Features  True Positive  False Negative  False Positive  \\\n",
       "1              50          17941              52            1874   \n",
       "2             151          17958               5            1941   \n",
       "3              50          17971              34            1859   \n",
       "4              50          17881             114            1794   \n",
       "5              50          17875             131            1799   \n",
       "6              50          17928               0             896   \n",
       "7             151          17974               0             871   \n",
       "8              50          18011               1             895   \n",
       "9              50          17978              27            1908   \n",
       "10             50          17908             113            1773   \n",
       "\n",
       "    True Negative  Accuracy Score  \n",
       "1             133         0.90370  \n",
       "2              96         0.90270  \n",
       "3             136         0.90535  \n",
       "4             211         0.90460  \n",
       "5             195         0.90350  \n",
       "6            1176         0.95520  \n",
       "7            1155         0.95645  \n",
       "8            1093         0.95520  \n",
       "9              87         0.90325  \n",
       "10            206         0.90570  "
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(final, columns = ['# of Features', 'True Positive', 'False Negative', 'False Positive', \n",
    "                               'True Negative', 'Accuracy Score'], index = range(1, 11))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The optimal Models seem to be model 6, 7, and 8. These do not seem to be overfit. I will chose model 6 sinceI believe that the feature selection technique from model 1 is the most optimal because I believe that ANOVA performs the best connection to rank features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data2 = pd.read_csv('test.csv').drop(columns = ['ID_code'])\n",
    "# target = pd.read_csv('test_target.csv').drop(columns = ['ID_code'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2 = data2[data2.columns[keep]]\n",
    "data2 = data2[data2.columns[lr_1.get_support()]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = m6.predict(data2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[197658   2342]\n",
      " [     0      0]]\n",
      "accuracy score 0.988\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(target, x_test))\n",
    "print('accuracy score %.3f' %(accuracy_score(target, x_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model recieves a high rating of .985. However, the test data appears to be very skewed since I predicted 0 false positives and 0 True Negatives which indicates that the target consists of all 0's. Unfortunetely, I guess this indicates that our training data (20% ones) is not an accurate subset of the given target data (0% ones)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
